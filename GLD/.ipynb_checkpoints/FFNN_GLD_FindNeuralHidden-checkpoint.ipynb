{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import sqrt \n",
    "import time\n",
    "\n",
    "#Tien Xu Ly\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Draw Flot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Cacuale error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#distance Libaray\n",
    "from dtw import *\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cityblock\n",
    "\n",
    "#FFNN Libarary\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc Dữ Liệu\n",
    "# @param   filePath     Đường dẫn tập dữ liệu CSV\n",
    "# @return  df           Tập dữ liệu csv dưới dạng df\n",
    "def readData(filePath):\n",
    "    # Load dữ liệu\n",
    "    dataCSV = pd.read_csv(filePath)\n",
    "    df=dataCSV[['GLD']]\n",
    "    return df\n",
    "\n",
    "# Tiền Xử lý Dữ Liệu\n",
    "# @param  Data   Tập dữ liệu\n",
    "# @return df     Dữ liệu đã được tiền xử lý\n",
    "def cleanData(df):\n",
    "    # Replace null values with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    # Remove outliers by replacing values outside of 10 standard deviations with the mean\n",
    "    # std = df['GLD'].std()\n",
    "    # mean = df['GLD'].mean()\n",
    "    # df['GLD'] = np.where(df['GLD'] > (mean + 10*std), mean, df['GLD'])\n",
    "    # df['GLD'] = np.where(df['GLD'] < (mean - 10*std), mean, df['GLD'])\n",
    "    # Scale data_AMZN to range [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    df['GLD'] = scaler.fit_transform(df['GLD'].values.reshape(-1, 1))\n",
    "    # Fill in missing values with the mean of the previous and next values\n",
    "    df['GLD'] = df['GLD'].interpolate(method='linear')\n",
    "    return df\n",
    "\n",
    "# Chia dữ liệu thành train set và test set\n",
    "# @param  data                      Tập dữ liệu\n",
    "# @param  percentTrain              Tỷ lệ Tập train\n",
    "# @return train_data, test_data     Tập train và test   \n",
    "def splitData(data, percentTrain):\n",
    "    train_size = int(len(data) * (percentTrain/100))\n",
    "    train = data.iloc[:train_size, :]\n",
    "    test = data.iloc[train_size:, :]\n",
    "    return train, test\n",
    "\n",
    "# Xử lý dữ liệu thành dữ liệu đầu vào và đầu ra cho mô hình\n",
    "# @param      data            Dữ liệu cần chia cửa sổ\n",
    "# @param      size_window     Kích thước cửa sổ\n",
    "# @param      size_predict    Kích thước cửa sổ dự đoán\n",
    "# @param      stepWindow      số điểm dữ liệu trượt\n",
    "# @return     X, y            mảng cửa sổ mẫu và mảng điểm dự đoán tương ứng\n",
    "def prepare_data(data, size_window, size_predict, stepWindow):\n",
    "    X, y = [], []\n",
    "    startWindow = 0\n",
    "    for i in range(len(data) - size_window - 1):\n",
    "        if (len(data[(startWindow + size_window):(startWindow + size_window + size_predict) , 0]) != size_predict):\n",
    "            break\n",
    "        X.append(data[startWindow:(startWindow + size_window), :])\n",
    "        y.append(data[(startWindow + size_window):(startWindow + size_window + size_predict) , 0])\n",
    "        startWindow += stepWindow\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#---------KNN-----------\n",
    "# Fucntion Tính khoảng cách giữa 2 chuỗi thời gian\n",
    "# @param    ts1            Chuỗi thứ nhất\n",
    "# @param    ts2            Chuỗi thứ hai\n",
    "# @return   euclidean      Khoảng cách euclidean    \n",
    "def euclidean_distance(ts1, ts2):\n",
    "    ts1= ts1.flatten()\n",
    "    ts2= ts2.flatten()\n",
    "    return euclidean(ts1,ts2)\n",
    "\n",
    "# Function lấy ra k chuỗi gần nhất\n",
    "# @param    k             Số lượng chuỗi gần nhất\n",
    "# @param    distanceArr   Mảng khoảng cách\n",
    "# @return   argsort       Vị trí chuỗi gần nhất        \n",
    "def kSimilarityTimeSeries(k, distanceArr):\n",
    "    distances = np.array(distanceArr)\n",
    "    return distances.argsort()[:k] \n",
    "\n",
    "# Tính khoảng cách DTW\n",
    "# @param    ts1            Chuỗi thứ nhất\n",
    "# @param    ts2            Chuỗi thứ hai\n",
    "# @return   euclidean      Khoảng cách euclidean  \n",
    "def dtw_dist(ts1, ts2):\n",
    "    dist, _ = fastdtw(ts1, ts2, dist=cityblock)\n",
    "    return dist\n",
    "\n",
    "# Thêm Dữ liệu\n",
    "# @param    X_train               Cửa sổ mẫu train\n",
    "# @param    y_train               Cửa sổ dự đoán train\n",
    "# @param    XTest                 Cửa sổ mẫu test\n",
    "# @param    yTest                 Cửa sổ dự đoán test\n",
    "# @return   X_train, y_train      Khoảng cách euclidean \n",
    "def toTrain(X_train, y_train, XTest, yTest):\n",
    "    X_train.append(XTest)\n",
    "    y_train.append(yTest)\n",
    "    return np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Dự đoán Euclidean\n",
    "# @param    nameData           Tên tập dữ liệu\n",
    "# @param    k                  Số lượng chuỗi gần nhất\n",
    "# @param    typeDistance       Độ đo sử dụng (Dtw, euclidean)\n",
    "# @param    X_train            Cửa sổ mẫu train\n",
    "# @param    y_train            Cửa sổ dự đoán train\n",
    "# @param    X_test             Cửa sổ mẫu test\n",
    "# @param    y_test             Cửa sổ dự đoán test\n",
    "# @return   y_pred_arr         Mảng dự đoán\n",
    "def predict_KNN(k, typeDistance, X_train, y_train, X_test, y_test):\n",
    "    y_pred_arr=[]\n",
    "    for iTest in range(len(X_test)):\n",
    "        if(k>len(X_train)):\n",
    "            k=len(X_train)\n",
    "        distanceArr=[]\n",
    "        for iTrain in range(len(X_train)-size_window+2):\n",
    "            if(typeDistance == 'Dtw'):\n",
    "                distance = dtw_dist(X_test[iTest],X_train[iTrain])\n",
    "            else:\n",
    "                distance = euclidean_distance(X_test[iTest],X_train[iTrain])\n",
    "            distanceArr.append(distance)\n",
    "        indexKNN= kSimilarityTimeSeries(k,distanceArr)\n",
    "        y_pred = np.mean(y_train[indexKNN])\n",
    "        y_pred_arr.append(y_pred)\n",
    "        X_train, y_train = toTrain(X_train.tolist(), y_train.tolist(),X_test[iTest].tolist(), y_test[iTest].tolist())\n",
    "        y_pred = np.array(y_pred_arr)\n",
    "   \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "#----------------FFNN--------------------------\n",
    "# Khởi tạo mô hình FFNN\n",
    "# @param    neuralInput         Kích thước Cửa sổ mẫu/ số neural lớp input\n",
    "# @param    num_layers_hidden   Số lượng lớp ẩn\n",
    "# @param    num_neural_hidden   Số neural lớp ẩn\n",
    "# @param    neuralOutput         Số neural lớp ouput\n",
    "# @return   model               Mô hình FFNN\n",
    "def create_model_FFNN(neuralInput, num_layers_hidden=1, neuralHidden=1, neuralOutput=1):\n",
    "    model = Sequential()\n",
    "    for i in range(num_layers_hidden):\n",
    "        if i == 0:\n",
    "            model.add(Dense(neuralHidden, input_dim= neuralInput, activation='sigmoid'))\n",
    "        else:\n",
    "            model.add(Dense(neuralHidden, activation='sigmoid'))\n",
    "    model.add(Dense(neuralOutput))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train FFNN \n",
    "# @param    nameData          Tên tập dữ liệu\n",
    "# @param    size_window       Kích thước Cửa sổ mẫu/ số neural lớp input\n",
    "# @param    X_train           cửa sổ mẫu tập train\n",
    "# @param    y_train           Cửa sổ dự đoán tập train\n",
    "# @param    neuralHidden      Số neural lớp ẩn\n",
    "# @param    numHiddenLayer    Số lớp ẩn\n",
    "# @param    size_predict      Kích thước Cửa sổ dự đoán/ Số neural lớp ouput\n",
    "# @return   best_params_FFNN  Tham số tốt nhất cho mô hình FFNN                \n",
    "def train_FFNN(nameData, typePredict, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict):\n",
    "    #param search\n",
    "    param_grid_FFNN = {'batch_size': [8, 16, 32, 64, 128],\n",
    "              'epochs': [50, 100, 150, 200, 250, 300],\n",
    "              'neuralHidden': [neuralHidden],\n",
    "              'num_layers_hidden' : [numHiddenLayer],\n",
    "              'neuralInput' : [size_window],\n",
    "              'neuralOutput' : [size_predict]}\n",
    "\n",
    "    # create the model\n",
    "    model_FFNN = KerasRegressor(build_fn=create_model_FFNN, verbose=0)\n",
    "    \n",
    "    # perform the grid search\n",
    "    grid_FFNN = GridSearchCV(estimator=model_FFNN, param_grid=param_grid_FFNN, cv=3)\n",
    "    grid_result_FFNN = grid_FFNN.fit(X_train, y_train)\n",
    "    \n",
    "    # train the model with the best parameters\n",
    "    best_params_FFNN = grid_result_FFNN.best_params_\n",
    "    \n",
    "    model_FFNN = create_model_FFNN( best_params_FFNN['neuralInput'], best_params_FFNN['num_layers_hidden'], best_params_FFNN['neuralHidden'],best_params_FFNN['neuralOutput'])\n",
    "    model_FFNN.fit(X_train, y_train, epochs=best_params_FFNN['epochs'], batch_size=best_params_FFNN['batch_size'], verbose=2, callbacks=[EarlyStopping(monitor='loss', patience=10)], shuffle=False)\n",
    "    \n",
    "    if(typePredict=='FFNN_Find_NeuralHidden'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NeuralHidden/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    else:\n",
    "        model_FFNN.save_weights('../BestParam/TuanTu/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    return best_params_FFNN\n",
    "\n",
    "\n",
    "\n",
    "# Train FFNN \n",
    "# @param    nameData          Tên tập dữ liệu\n",
    "# @param    size_window       Kích thước Cửa sổ mẫu/ số neural lớp input\n",
    "# @param    X_train           cửa sổ mẫu tập train\n",
    "# @param    y_train           Cửa sổ dự đoán tập train\n",
    "# @param    batchSize         Số lượng mẫu được đưa vào với mỗi lần lặp (epoch)\n",
    "# @param    epoch             Số lần lặp cập nhật trọng số\n",
    "# @param    neuralHidden      Số neural lớp ẩn\n",
    "# @param    numHiddenLayer    Số lớp ẩn\n",
    "# @param    size_predict      Kích thước Cửa sổ dự đoán/ Số neural lớp ouput\n",
    "# @return   best_params_FFNN  Tham số tốt nhất cho mô hình FFNN                \n",
    "def train_best_param_FFNN(nameData, typePredict, size_window, X_train, y_train, batchSize, epoch, neuralHidden, numHiddenLayer, size_predict):\n",
    "    #param search\n",
    "    param_grid_FFNN = {'batch_size': batchSize,\n",
    "              'epochs': epoch,\n",
    "              'neuralHidden': neuralHidden,\n",
    "              'num_layers_hidden' : numHiddenLayer,\n",
    "              'neuralInput' : size_window,\n",
    "              'neuralOutput' : size_predict}\n",
    "    \n",
    "    model_FFNN = create_model_FFNN( param_grid_FFNN['neuralInput'], param_grid_FFNN['num_layers_hidden'], param_grid_FFNN['neuralHidden'],param_grid_FFNN['neuralOutput'])\n",
    "    model_FFNN.fit(X_train, y_train, epochs=param_grid_FFNN['epochs'], batch_size=param_grid_FFNN['batch_size'], verbose=2, callbacks=[EarlyStopping(monitor='loss', patience=10)], shuffle=False)\n",
    "    \n",
    "    if(typePredict=='FFNN_Find_NeuralHidden'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NeuralHidden/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer_SongSong'):\n",
    "        model_FFNN.save_weights('../BestParam/SongSong/'+nameData+'/FFNN_Find_BestWeights/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    else:\n",
    "        model_FFNN.save_weights('../BestParam/TuanTu/'+nameData+'/FFNN_Find_BestWeights/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "   \n",
    "    return param_grid_FFNN\n",
    "\n",
    "# Dự Đoán FFNN \n",
    "# @param    nameData          Tên tập dữ liệu\n",
    "# @param    typePredict       Thực hiện loại dự đoán (FFNN_Find_NeuralHidden,FFNN_Find_NumberHiddenLayer,CombinePredict)\n",
    "# @param    X_train           cửa sổ mẫu tập train\n",
    "# @param    y_train           Cửa sổ dự đoán tập train\n",
    "# @param    X_test            Cửa sổ dự đoán tập train\n",
    "# @param    best_params_FFNN  Cửa sổ dự đoán tập train\n",
    "# @return   predictions_FFNN  Mảng dự đoán\n",
    "def predict_FFNN(nameData, typePredict, X_train, y_train, X_test, best_params_FFNN):\n",
    "    model_FFNN1 = Sequential()\n",
    "    for i in range(best_params_FFNN['num_layers_hidden']):\n",
    "        if i == 0:\n",
    "            model_FFNN1.add(Dense(best_params_FFNN['neuralHidden'], input_dim= best_params_FFNN['neuralInput'], activation='sigmoid'))\n",
    "        else:\n",
    "            model_FFNN1.add(Dense(best_params_FFNN['neuralHidden'], activation='sigmoid'))\n",
    "    model_FFNN1.add(Dense(best_params_FFNN['neuralOutput']))\n",
    "    \n",
    "    if(typePredict=='FFNN_Find_NeuralHidden'):\n",
    "        model_FFNN1.load_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NeuralHidden/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer'):\n",
    "        model_FFNN1.load_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer_SongSong'):\n",
    "        model_FFNN1.load_weights('../BestParam/SongSong/'+nameData+'/FFNN_Find_BestWeights/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "    else:\n",
    "        model_FFNN1.load_weights('../BestParam/TuanTu/'+nameData+'/FFNN_Find_BestWeights/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.weights.h5')   \n",
    "   \n",
    "    model_FFNN1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    predictions_FFNN = model_FFNN1.predict(X_test)\n",
    "    return predictions_FFNN\n",
    "\n",
    "#---------------------Song Song------------------------------#\n",
    "\n",
    "# Lai Ghép Song Song\n",
    "# @param    y_pred_FFNN     Mảng dự đoán của FFNN\n",
    "# @param    y_pred_KNN      Mảng dự đoán của KNN\n",
    "# @param    y_test          Mảng chuỗi thực tế\n",
    "# @return   y_pred_combine  Mảng dự đoán kết hợp\n",
    "def predictHybrid(y_pred_FFNN,y_pred_KNN,y_test):\n",
    "    FFNNSubKNN=[]\n",
    "    TestSubKNN=[]\n",
    "    weightEl=[]\n",
    "    for i in range(len(y_pred_FFNN)):\n",
    "        FFNNSubKNN.append(y_pred_FFNN[i]-y_pred_KNN[i])\n",
    "        TestSubKNN.append(y_test[i]-y_pred_KNN[i])\n",
    "\n",
    "    for j in range(len(FFNNSubKNN)):\n",
    "        weightEl.append(((FFNNSubKNN[j]*TestSubKNN[j])/ (FFNNSubKNN[j]*FFNNSubKNN[j])))\n",
    "    \n",
    "    weight = np.array(weightEl)\n",
    "    \n",
    "    y_pred_combine=[]\n",
    "    for i in range(len(weight)):\n",
    "        y_pred_combine.append(weight[i]*y_pred_FFNN[i]+(1-weight[i])*y_pred_KNN[i])\n",
    "    y_pred_combine=np.array(y_pred_combine)\n",
    "    return y_pred_combine\n",
    "\n",
    "#---------------------Tuần Tự------------------------------#\n",
    "\n",
    "# Tính Lỗi Theo Từng Ngày\n",
    "# @param    y_pred_KNN      Mảng dự đoán của KNN\n",
    "# @param    y_test          Mảng chuỗi thực tế\n",
    "# @return   mseWithDay     Mảng lỗi theo ngày\n",
    "def mseWithDay(y_pred_KNN, y_test):\n",
    "    mseDay = []\n",
    "    for i in range(len(y_pred_KNN)):\n",
    "        mseDay.append([abs((y_test[i] - y_pred_KNN[i]))])\n",
    "    mseDay=np.array(mseDay)\n",
    "    return mseDay\n",
    "\n",
    "def predictSum(y_pred_mse,y_pred_KNN):\n",
    "    pred_knn_ffnn=[]\n",
    "    for i in range(len(y_pred_mse)):\n",
    "        pred_knn_ffnn.append(y_pred_KNN[i]+y_pred_mse[i])\n",
    "    pred_knn_ffnn=np.array(pred_knn_ffnn)\n",
    "    return pred_knn_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_best_param_FFNN() missing 2 required positional arguments: 'numHiddenLayer' and 'size_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neuralHidden \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m     19\u001b[0m     start_Train\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 20\u001b[0m     best_param \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_best_param_FFNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnameData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFFNN_Find_NeuralHidden\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuralHidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumHiddenLayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     end_Train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     23\u001b[0m     start_Test\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mTypeError\u001b[0m: train_best_param_FFNN() missing 2 required positional arguments: 'numHiddenLayer' and 'size_predict'"
     ]
    }
   ],
   "source": [
    "nameData= 'GLD'\n",
    "filePath= '../data/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "\n",
    "size_window = 5\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "\n",
    "numHiddenLayer = 1\n",
    "df_MseWith_Neural = pd.DataFrame([],  columns =  [\"Neural Hidden\",\"Batch_Size\",\"Epoch\", \"MSE\",\"Time Train\", \"Time Test\", \"Total Time\"])\n",
    "\n",
    "for neuralHidden in range(1,21):\n",
    "    \n",
    "    start_Train= time.time()\n",
    "    best_param = train_best_param_FFNN(nameData, 'FFNN_Find_NeuralHidden', size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "    end_Train = time.time()\n",
    "    \n",
    "    start_Test= time.time()\n",
    "    predictions_FFNN= predict_FFNN(nameData, 'FFNN_Find_NeuralHidden', X_train, y_train, X_test, best_param)\n",
    "    end_Test = time.time()\n",
    "\n",
    "    timeTrain = end_Train - start_Train\n",
    "    timeTest = end_Test -  start_Test\n",
    "    totalTime = timeTrain+ timeTest\n",
    "    \n",
    "    rowMseWithNeural = pd.DataFrame([[numHiddenLayer,neuralHidden,best_param['batch_size'],best_param['epochs'], mean_squared_error(y_test , predictions_FFNN), timeTrain, timeTest, totalTime]], columns=df_MseWith_HiddenLayer.columns)\n",
    "    df_MseWith_Neural = pd.concat([df_MseWith_Neural,rowMseWithNeural],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number Hidden Layer</th>\n",
       "      <th>Neural Hidden</th>\n",
       "      <th>Batch_Size</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Time Train</th>\n",
       "      <th>Time Test</th>\n",
       "      <th>Total Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>9.586905</td>\n",
       "      <td>0.390575</td>\n",
       "      <td>9.977480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>10.783477</td>\n",
       "      <td>0.382345</td>\n",
       "      <td>11.165822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>4.489076</td>\n",
       "      <td>0.632233</td>\n",
       "      <td>5.121309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>4.345142</td>\n",
       "      <td>0.494290</td>\n",
       "      <td>4.839432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>17.666380</td>\n",
       "      <td>0.780918</td>\n",
       "      <td>18.447298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>32.307329</td>\n",
       "      <td>0.619208</td>\n",
       "      <td>32.926537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>25.205939</td>\n",
       "      <td>0.403798</td>\n",
       "      <td>25.609737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>6.688734</td>\n",
       "      <td>0.507807</td>\n",
       "      <td>7.196541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>42.271075</td>\n",
       "      <td>0.500317</td>\n",
       "      <td>42.771392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>7.048145</td>\n",
       "      <td>0.713931</td>\n",
       "      <td>7.762077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>8.459752</td>\n",
       "      <td>0.813485</td>\n",
       "      <td>9.273236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>8.626250</td>\n",
       "      <td>0.759537</td>\n",
       "      <td>9.385787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>9.329462</td>\n",
       "      <td>0.711648</td>\n",
       "      <td>10.041110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>11.891884</td>\n",
       "      <td>0.808481</td>\n",
       "      <td>12.700365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>9.520254</td>\n",
       "      <td>0.854062</td>\n",
       "      <td>10.374316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>57.152143</td>\n",
       "      <td>0.876577</td>\n",
       "      <td>58.028720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>12.964864</td>\n",
       "      <td>2.149199</td>\n",
       "      <td>15.114063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>10.723437</td>\n",
       "      <td>0.857552</td>\n",
       "      <td>11.580989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>9.875852</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>10.757553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>10.164973</td>\n",
       "      <td>0.883558</td>\n",
       "      <td>11.048531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number Hidden Layer Neural Hidden Batch_Size Epoch       MSE  Time Train  \\\n",
       "0                    1            13         32   200  0.000171    9.586905   \n",
       "1                    2            13         32   200  0.001121   10.783477   \n",
       "2                    3            13         32   200  0.007730    4.489076   \n",
       "3                    4            13         32   200  0.009516    4.345142   \n",
       "4                    5            13         32   200  0.006978   17.666380   \n",
       "5                    6            13         32   200  0.000686   32.307329   \n",
       "6                    7            13         32   200  0.000295   25.205939   \n",
       "7                    8            13         32   200  0.010214    6.688734   \n",
       "8                    9            13         32   200  0.004379   42.271075   \n",
       "9                   10            13         32   200  0.008857    7.048145   \n",
       "10                  11            13         32   200  0.009787    8.459752   \n",
       "11                  12            13         32   200  0.007533    8.626250   \n",
       "12                  13            13         32   200  0.007418    9.329462   \n",
       "13                  14            13         32   200  0.009681   11.891884   \n",
       "14                  15            13         32   200  0.010041    9.520254   \n",
       "15                  16            13         32   200  0.005620   57.152143   \n",
       "16                  17            13         32   200  0.009174   12.964864   \n",
       "17                  18            13         32   200  0.009373   10.723437   \n",
       "18                  19            13         32   200  0.009277    9.875852   \n",
       "19                  20            13         32   200  0.008997   10.164973   \n",
       "\n",
       "    Time Test  Total Time  \n",
       "0    0.390575    9.977480  \n",
       "1    0.382345   11.165822  \n",
       "2    0.632233    5.121309  \n",
       "3    0.494290    4.839432  \n",
       "4    0.780918   18.447298  \n",
       "5    0.619208   32.926537  \n",
       "6    0.403798   25.609737  \n",
       "7    0.507807    7.196541  \n",
       "8    0.500317   42.771392  \n",
       "9    0.713931    7.762077  \n",
       "10   0.813485    9.273236  \n",
       "11   0.759537    9.385787  \n",
       "12   0.711648   10.041110  \n",
       "13   0.808481   12.700365  \n",
       "14   0.854062   10.374316  \n",
       "15   0.876577   58.028720  \n",
       "16   2.149199   15.114063  \n",
       "17   0.857552   11.580989  \n",
       "18   0.881701   10.757553  \n",
       "19   0.883558   11.048531  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MseWith_HiddenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
